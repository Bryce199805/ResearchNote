# Deep Learning Turning Playbook

https://github.com/google-research/tuning_playbook



## Optimizer

建议使用完善的、流行的优化器，在理想情况下，选择同类型问题中最流行的优化器，要准备好该优化器的所有参数，参数比较多的优化器可能需要很多调整工作才能找到最佳配置，在项目的初始阶段，最好从比较简单的优化器开始，然后切换到更通用的优化器

**如何调整Adam的超参数？**并非Adam中所有的超参数都同等重要，这里的实验应该是指进行调参的试验次数 

> 如果实验的次数小于10次。仅调整基本学习率
>
> 如果进行10-25次实验，调整学习率和β1
>
> 进行25+次实验，调整学习率、$\beta_1$和$\epsilon$
>
> 如果可以运行超过25次实验，可以另外调整$\beta_2$



## Batch Size大小的设置

批量大小决定训练速度，不应用于直接调整验证集性能，理想的批量大小通常是可用**硬件支持的最大批量大小**

> 批量大小是决定训练时间和计算资源消耗的关键因素
>
> 增加批量大小通常会减少训练时间，他通常可以允许在固定时间间隔内更彻底的调整超参数，可能会产生更好的最终模型
>
> 批量大小的调整**不应该被视为验证集性能的可调节超参数**，只要所有超参数都经过良好调整且训练步骤足够，任何批量大小都应该可以获得相同的最终性能。

***为什么不应该调整批量大小来直接提高验证集性能？***

在不更改训练过程的其他参数的情况下更改批量大小通常会影响验证集的性能，然而针对每个批量大小都进行独立的训练参数优化则这两者之间的差异会消失。因此要针对每个批量大小单独调整最重要的是优化器的超参数（例如学习率和动量）以及正则化超参数。这是由于样本方差，**较小的批量大小会在训练算法中引入更多的噪声**，并且这种噪声可以产生正则化效果，因此**较大的批量大小可能更容易出现过拟合的问题**，需要更强的正则化或额外的正则化技术。

更改批量大小时可能还需要**调整训练步骤数**

考虑以上所有的影响，没有什么证据能够证明批量大小能够影响验证集的性能。



### 确定可行批量大小并估计训练吞吐量 		------***最大化训练吞吐量***

对于给定的模型和优化器，批量大小的限制因素通常是**硬件加速器的内存**，通常时通过**不同批量大小（例如2的幂次递增）**运行少量步骤的训练，直到某一步超出可用内存。

对于每个批量大小，应当训练足够的时间来获得训练吞吐量的估计:

​	训练吞吐量 = **每秒处理的示例数量** 或 **每一步的时间**

​	这两者可以相互转化  每步时间 =  批量大小 / 每一步处理的实力数量

当加速器尚未饱和时，**批量大小加倍**，**训练吞吐量也应该接近加倍**；随着批量大小的增加，**每个步骤的时间应该接近恒定**

如果情况并非如此，则**训练流程可能存在瓶颈**，例如计算节点之间的I/O同步，**优先考虑处理这部分问题**

训练吞吐量**仅增加到某个最大批量大小**，则我们**应当将批量大小设定为该值**，即使硬件可以支持更大的批量大小

> 即使用更大的批量大小没有增加训练的吞吐量，则修复训练流程的瓶颈或使用较小的批量大小

每次修改模型或优化器时，可能都要重复则和谐步骤，因为不同的模型架构可能允许更大的批量大小



### 选择批量大小以最小化训练时间		------***最小化训练时间***

​	训练时间 = 每步时间 * 总步数

我们认为对于所有可行的批量大小，当并行计算没有开销并且所有训练瓶颈都已被纠正，每步是时间接近恒定，但是在实践中批量大小通常会产生一些开销。随着批量大小的增加，达到固定性能目标所需的总步数通常会减少

> 例如将批量大小加倍可能会使所需的总步骤数减半，这成为完美放缩
>
> 完美放缩**适用于直到临界批量大小的所有批量**，**超过**该批量大小就会出现**收益递减**

因此最小化训练时间的批量大小通常是减少所需训练步骤数量的最大批量大小，如果最终会**增加训练时间**，则**使用更大的批量大小是没有意义的**。



### 更改批量大小需要调整大多数超参数		------***尽量不要改变批量的大小***

大多数**超参数的最优值是对批量大小敏感的**，因此更改批量大小需要重新调整训练过程，其中最重要的参数是优化器的参数和正则化的参数，因此切换不同大小的批量大小是困难耗时且费力的，尽量不要改变批量的大小！



### 批量标准化与批量大小的相互作用		------***移至batch norm模块讨论***

pass



## 选择初始化配置	***------so how to initialize?***

首先我们要确定模型配置，优化器超参数，以及训练步数，确定这些配置需要一些手动配置的训练和试错，我们目的是为了找到一种简单、相对快捷、资源消耗相对较低的配置，从而获得合理的结果。

> **简单意味着尽可能的避免花哨的东西**，这些可以随时添加，即使这些设置是有用的，但是将他们添加到初始配置可能会浪费时间调整无用的功能和陷入复杂的情况。例如从恒定的学习率开始而不是添加花哨的学习率衰减时间表。
>
> **选择快速且消耗最少资源的初始配置将使超参数调整更加高效**，例如可以从较小的模型开始，小模型能够快速验证和迭代，节约计算资源，通过**在小模型上进行实验**，可以**得到哪些超参数对模型性能产生更大影响的指导信息**，虽然在转移到更大模型时需要重新调整超参数，**从较小模型作为起点可以加速整个调优过程**。
>
> 合理的性能取决于具体问题，但至少经过训练的模型在验证集上的性能要比随机的结果好得多。

在选择训练步骤时需要权衡以下问题：

> 更多的训练可以提高性能病逝超参数调整更容易
>
> 训练更少的步骤意味着每次训练运行速度更快并且使用更少的资源，通过减少周期之间的时间并允许并行运行更多实验来提高调优效率
>
> 另外如果最初选择了不必要的大步骤，那么随后进行的调整可能会比较困难，例如学习率针对该步数进行调优可能会有比较大的开销



## 提高模型性能的科学方法

大多数自动搜索算法依赖于手动设计的搜索空间，该搜索空间定义了要搜索的配置集，并且这些搜索空间可能非常重要**。最大限度地提高性能的最有效的方法是从简单的配置开始**，**逐步添加功能并进行改进**，同时深入了解问题，在每一轮调整中都使用自动搜索算法，并随着我们理解的增长**不断更新我们的搜索空间**。增量调整策略主要有以下四个步骤：

> 为下一轮实验确定适当范围的目标
>
> 设计并运行一组实验，以朝着这一目标取得进展
>
> 从结果中了解我们能得到什么
>
> 考虑是否能够推出新的最佳配置

在进行调参时大部分时间是用在探索之上，**确定哪些超参数对验证集错误最敏感**、**哪些超参数相互作用最多**以及**哪些超参数对其他变化不敏感**，将有利于我们的参数调整。识别**没有帮助的功能**，并将其删除，从而降低未来实验的复杂性。

### 选择下一轮实验的目标

每轮实验都应有**明确的目标**，并且范围足够窄，以便实验能够朝着目标取得进展

实验的目标示例：

> 尝试对训练过程的潜在改进 例如新的正则化器，预处理的操作等
>
> 了解特定模型超参数的影响 如激活函数对结果的影响
>
> 最小化验证错误

### 设计下一轮实验

针对实验目标确定哪些超参数是敏感的、不敏感的和固定的超参数。创建一系列研究来比较敏感超参数的不同值，同时优化不敏感的超参数使之达到最好的效果。

> 科学/敏感的超参数是那些对我们模型产生影响的超参数；扰的超参数对模型的目标性能影响比较小但需要优化来更好的比较敏感超参数的不同值；固定超参数的值在本轮实验中固定不变。
>
> 例如：如果我们的目标是“**确定具有更多隐藏层的模型是否会减少验证误差**”，那么**隐藏层的数量就是一个敏感的超参数**，**学习率此时就是一个干扰的超参数**，因为我们只有在对每层单独调整学习率才能对层数进行公平的比较（因为最佳的学习率取决于模型架构）；如果我们在之前的实验中能确定激活函数的选择对模型的深度不敏感，或者我们愿意限制其为固定的值，则**激活函数可以是固定的超参数**，或者我们准备为每个隐藏层单独调整他，此时他是一个干扰参数。
>
> 这些超参数是**科学的超参数、干扰的超参数和固定的超参数是根据实验目的而变化的**。例如，激活函数的选择可以是一个科学超参数（ReLU 或 tanh 是我们问题的更好选择吗？），一个干扰超参数（当我们允许多个模型时，最好的 5 层模型是否比最好的 6 层模型更好）或固定的超参数（对于 ReLU 网络，在特定位置添加批量归一化有帮助吗？）。
>
> 首先我们要确定实验目标的**科学超参数**；然后视其他参数为干扰参数，然后再将一些干扰参数固定为固定的超参数。给定的干扰超参数与科学超参数相互作用越多，将其固定的破坏性就越大。

针对某些类别的超参数，我们有以下的经验法则：

> 在各种**优化器超参数**（学习率 动量 学习率计划 adam beta等）**至少其中一项是干扰超参数**，因为他们往往与其他更改交互较多，他们**很少成为科学的超参数**，因为诸如“当前管道的最佳学习率是多少”这类的目标并没有提供太多有用的见解，因为他们很容易随着下一次训练过程的变化而变化。
>
> 我们通常**不会固定优化器超参数**，他们**应当单独调整**，以便在不同的设置之间公平的比较其他超参数的影响。

> **优化器的选择**可以是**科学超参数也可以是固定超参数**，如果我们的实验目标是在多个不同优化器之间进行比较，则他是一个科学超参数；我们也可将其设为固定超参数，原因可以是先前实验证明我们的问题目标对优化器的选择不敏感；或这个优化器的训练曲线能让我们更好的推理当前问题科学超参数的设置；或该优化器能节约更多的资源

> 正则化计入引入的超参数通常是干扰超参数，而是否包含该正则化技术通常是一个科学或固定的超参数，例如dropout增加了代码的复杂性，我们会将是否添加dropout层视为科学超参数，dropout率则设为干扰超参数

> 在某些情况下，干扰和固定超参数通常取决于科学超参数的值

### 创建一组实验

在我们确定好各类超参数的所属后，设计一系列实验来朝着我们的实验目标进行

> 在最简单的情况下，我们将对科学参数的**每种配置进行单独的研究**，其中每项研究都会对干扰参数进行单独调整
>
> 在更复杂的情况下，我们想要比较大量科学超参数的值，并且进行如此多的独立研究是不切实际的，我们可以**将科学参数和干扰参数包含在同一搜索空间中**，并使有搜索算法在一次实验中对科学超参数和干扰超参数的值**进行采样**

**在信息丰富和消耗的资源之间取得平衡**

设计一组实验并分配有限的预算，我们通常有以下三个愿景：

> **比较足够多的科学超参数的不同值**
>
> **在足够大的搜索空间上调整干扰参数**
>
> **对干扰参数的搜索空间进行足够密集的采样**

我们对以上三条实现的越充分，就能从实验中获得更多的知识

> 尽可能多的科学超参数能扩大我们从实验中获得经验知识的范围
>
> 在科学超参数的每种配置的搜索空间尽可能多的搜索干扰超参数的值能增加我们的“自信”，否则实验中可能会出现不公平的比较

对这三个维度任何改进都会增加实验的次数从而增加成本，对这些需求分配资源时需要一定的领域知识，在进行一项实验之后需要了解该实验是否足够好地调整了干扰参数以公平的比较了科学超参数



### 从实验结果中提取经验知识

除了努力实现每组实验的最初目标之外，还应该**检查附加问题清单**，如果发现问题应及时修改实验。

每组实验都有一个特定的目标，我们希望评估实验为实现该目标提供证据，在这个过程中我们**经常会发现一些需要纠正的问题**，然后给定一组实验验证才能朝着最初的目标发展，如果我们忽略他们往往会得到错误的结论，这份问题清单通常包括以下几个内容：

> ***搜索空间足够大么？***
>
> 如果实验的最佳点靠近搜索空间的边界，则可能搜索空间不够大，我们应当扩展搜索空间继续实验。
>
> 通常绘制目标值与超参数的关系图，红叉表示的是实验组中不可行的实验；我们希望**最好的结果在搜索空间的中心区域**
>
> ![image-20231226170246334](./imgs/image-20231226170246334.png)
>
> ***是否在搜索空间中采样了足够的点？***
>
> 如果没有，则进行更多的实验或是降低本轮实验的目标
>
> 一般来说我们很难知道我们的采样是否足够密集，更多的实验会带来更大的开销，我们通常**采样我们可以负担得起的样本量**进行实验，并观察**超参数图有多少点落在了良好范围内**来估计我们的采样是否足够。
>
> ***每组实验中哪些实验是不可行的？*** 即实验出现分歧、损失非常糟糕或无法收敛的情况
>
> 若实验中有很大一部分点不可行，则应尝试调整搜索空间避免对他们进行采样；且在有些情况下，大量的不可行点可能训练代码中存在错误
>
> ***模型中是否存在优化问题？***
>
> 如果模型存在优化问题，则在进行其他工作之前解决它很重要
>
> 如果学习率太大，任何工作负载都会变得不稳定，只有当不稳定迫使我们使用太小的学习率是，不稳定才会成为一个问题，至少有两种类型的不稳定值得区分:
>
> > 初始化/训练早期不稳定
> >
> > 训练途中突然不稳定
>
> > 我们可以采取系统的方法识别实验中的稳定性问题
> >
> > 进行学习率扫描找到最佳的学习率lr*
> >
> > 绘制略高于lr*的学习率的损失曲线
> >
> > 如果学习率 > lr* 显示损失不稳定（在训练期间上升而不是下降），则修复不稳定性可能会带来更好的训练效果
>
> 在训练期间记录梯度的L2范数，异常值可能会导致训练过程中虚假不稳定性。
>
> ​	***常见的不稳定模式修复方法***
>
> ​	**应用学习率预热**	---最适合早期训练的不稳定，学习率**预热的最大值**要比已经确定的不稳定的学习率大一个数量级，预热的**可行点不应超过迭代次数的10%**
>
> ​	**应用梯度裁剪**	---对于早期和中期的不稳定（梯度突然的峰值波动）都有好处，可以修复一些预热无法解决的不良初始化。发生**大的或离群的梯度问题**时，梯度裁剪最有效；裁剪为**梯度的90%**是一个很好的起点，我们认定超过50%的梯度裁剪为激进的，如果需要**激进的梯度裁剪，不妨降低学习率**。
>
> ​	**尝试新的优化器**	---有时Adam可以处理Momentum无法处理的不稳定情况
>
> ​	**确保模型架构最佳**	---如果模型不包含残差连接和标准化，则添加上残差连接和标准化
>
> ​	**归一化应当是残差连接之前的最后一个操作**	eg.  x+ Norm(f(x))  Norm(x + f(x)) 会导致一些问题
>
> ​	**尝试将残差连接分支初始化为0** 
>
> ​	**降低学习率**	---这是最后的手段
>
> ***我们能从最佳的训练曲线中学到什么？***
>
> 例如最好的训练曲线是否与有问题的过拟合曲线一致？
>
> 检查训练曲线可以帮助我们确定下一步要采取的行动顺序，检查曲线时我们应关注以下问题：
>
> ​	***是否有任何实验表现出过拟合的问题？***
>
> ​	当**验证误差在某个时刻开始增加**时说明存在过拟合的问题，如果出现我们应当**调整我们的正则化技术**来重新实验
>
> ​	然而任何**使训练变得糟糕的设定都可能成为正则化因素**，即使他本意并非如此，因此我们必须意识到每**个科学超参数的最佳实验可能会诱使某些干扰超参数选择一个不好的值**
>
> ​	***训练后期的训练或验证误差是否有较大的逐步方差？***
>
> ​	如果是这样，这可能会**干扰我们比较不同科学超参数**以及我们找到的最佳结果的能力，因为这些**结果可能是以“幸运”或“不幸运”的步骤结束**，很难反应真实的情况
>
> ​	造成这种问题可能是因为批次方差较大、验证集较小或训练后期学习率较大，我们可以通过增大学习率、获取更多验证数据或使用学习率衰减来缓解
>
> ​	***训练结束后实验是否仍然有效改善？***
>
> ​	如果是这样，说明我们还可以通过增加训练步数或改变学习率来获得更好的效果
>
> ​	***训练结束之前，训练和验证集的性能是否已经饱和？***
>
> ​	如果是这样，我们可以减少训练的步骤
>
> ​	***训练中训练损失的增加也可以说明训练过程出现错误***



### 确定是否采用训练过程的更改或超参数的配置

在决定是否更改模型或训练程序或采用新的超参数配置时，我们需要了解不同结果中差异的来源。候选更改与我们最初的配置相比可能有更好的结果，但是在重复实验之后没有得到一致的优势，造成这种问题的原因可能有以下几类：

> 我们在使用相同超参数但使用不同随机种子初始化引起的方差
>
> 我们选择超参数的过程引起的结果变化，如使用特定搜索空间，但使用两个不同的种子进行准随机搜索导致最终选择的超参数值不同
>
> 数据收集和采集的方差，即数据集随即划分为训练、验证和测试集的方差，或由训练数据生成过程而产生的方差

我们为得到某个超参数的**最佳结果**时应关注他们的**方差**，因此在考虑应用候选更改时，应多运行几次来表征每次运行的方差。另外我们应该之采取那些改进效果超过其增加的复杂性的设定改变。



### 探索结束后

一旦我们完成了对良好搜索空间的探索并决定了应该调整哪些超参数，贝叶斯优化工具就是一个很好的选择

此时我们优先事项就**从更多的了解调整问题转而为生成最佳配置**，应该设计一个更精细的搜索空间，它包含最佳配置周围的区域且进行了充分的采样。

**探索的工作揭示了最重要的要调整的超参数以及他们的合理范围**，我们通过他来构建搜索空间，然后尽可能的转为**自动化的搜索**，各种用于调整机器学习模型的算法就比较适合，其中就包括贝叶斯优化算法。



## 确定每次训练的步数

有两种类型的训练，训练受计算限制和训练不受计算限制

当计算受到计算限制时，在这种情况下，如果我们能够训练更长时间，应该可以得到耕地的训练损失，并且通过适当的调整可以改善验证损失。此时最佳的训练时间永远是我们能负担得起的最长时间。

当计算不受限制时，我们可以按照自己的意愿进行训练，且某些时候训练更长时间不会有太大的帮助甚至会出现过拟合的问题，此时慷慨的训练时间可以使调整变得容易，特别是在调整学习率计划时，将时间表调整的完美，才能获得更好的错误率。



### 当训练不受计算限制时训练多长时间？

选择一个最大训练步数，应用于所有实验，如果训练步数总是在训练的前10%，则最大步数太大，若始终出现在后25%。则更大的步数或者调整学习率计划可能会有效。

如果模型中引入了数据增强或正则化技术，我们可能需要增加最大训练步数；而我们使用更好调整的优化器或更好的学习率计划，则可以减少最大步数。

### 当训练收计算限制时决定训练多长时间

建议进行两轮调整：

> round1 ： 更短的运行时间来找到好的模型和优化器超参数
>
> round2 ：在找到的比较好的超参数上进行长时间训练得到最佳模型

最大的难题是如何调整学习率的衰减表。

**Round 1**

在训练长度显著增加时，在简短的、不完整的训练中找到良好的超参数是不错的选择，我们希望在较短运行中发现的超参数的值可以转移到较长的训练中，对于迁移性给出以下总结：

> ***转移可能性很大***	---热身长度  初始化选择
>
> ***很可能会转移*** 	---模型架构 通常能成功转移，但也有很多反例
>
> ***或许会转移***	---优化器超参数 数据增强 正则化  我们认为这些东西会“松散的转移” ，但肯定要比上一条要弱
>
> ***不太可能转移***	---学习率计划表

**Round 2**

运行第一轮选出的最佳配置，保留固定初始的衰减长度，然后延长后续的lr周期吗，理想的方法是城北的增加运行时间



## 批量归一化的实现细节	***---主要在多设备上，对我没啥影响***

BatchNorm通常可以用LayerNorm来替换，但在不能替换时更改批量大小或主机数量可能会出现一些棘手的问题



## FAQS

### 我应该使用哪种学习率衰减作为默认值？

通常设定为线性衰减或余弦衰减

### 为什么有些论文的学习率表很复杂？

具有复杂学习率表的文章并不罕见，他们制作的一般过程为：

> 使用一些简单的LR衰减策略开始训练
>
> 训练直到性能停滞，此时暂停训练来调整学习率计划，重复次过程来完善学习率计划

学习率计划通常不能直接复制，因为他对其他超参数敏感。

