# Recurrent neural network training with dark knowledge transfer

**[2016ICASSP CCF-B](https://ieeexplore.ieee.org/abstract/document/7472809)**	**no code**

在RNN上提出了一种基于知识迁移的训练算法，利用一个简单的DNN模型训练一个复杂的RNN模型，同时使用了软标签和硬标签，并且从正则化和预训练的视角讨论了这一方法

## Introduction

RNN的训练是非常低效的，这是由于高度非线性引起的目标函数的扭曲以及反向传播中梯度的消失和爆炸。

这项工作重点研究了LSTM，启发与logit匹配和暗知识蒸馏，提出了一种基于知识迁移的训练算法，这是与先前蒸馏相反的研究，我们视图从一个简单的DNN模型来训练一个复杂的RNN模型，我们将教师模型视为正则化来平滑学生模型的过程。

这实际上是一种新的训练方式，他可以扩展到任何模型架构。



## Method

暗知识以软标签的形式存在，逼近可以用于提升简单模型，还可以用于训练复杂模型，我们认为用软标签训练至少有两个优势：能够为模型提供更多信息；使训练更加可靠。

软标签提供不像硬标签那样确定的概率标签，这提供了不确定性，有利于学习那些易于混淆的目标

软标签模糊了类的决策边界，提供了更平滑的训练，软标签导致训练样本之间的梯度方差更小



## Discussion

### Regularization view

同时使用软硬标签可以表述为一个正则化的问题：
$$
\mathcal{L}(\theta) = \alpha\mathcal{L}_H(\theta) + \mathcal{L}_S(\theta)=\sum_i\sum_j(\alpha t_{ij} + p_{ij})ln(y_{ij}(\theta))
$$
其中$\theta$表示模型参数，$\mathcal{L}_H(\theta) , \mathcal{L}_S(\theta)$分别表示使用硬标签和软标签的损失，$\alpha$是权重参数，$\mathcal{L}_H(\theta)$是传统的有监督训练方式，$\mathcal{L}_S(\theta)$起到了正则化的作用，迫使学生模型来模仿教师模型，而这种正则化帮助RNN训练寻找与DNN产生相似目标的最优解，从而降低了过拟合和欠拟合的风险。



### Pre-training view

我们可以先用软标签训练一个合理的模型，再用硬标签对模型进行精细化，而不是同时训练软标签和硬标签的模型，通过这种方式迁移学习起到预训练的作用而常用的监督训练起到微调的作用。

软标签导致可靠的训练结果用于模型初始化，由于软标签所包含的信息辨别能力较低，因此用硬标签进行细化往往是有帮助的



**正则化视图和预训练视图是紧密相关的，预训练本质上是一种正则化，将模型放在参数空间的某个位置，在该位置可以更容易的达到良好的局部最小值。**